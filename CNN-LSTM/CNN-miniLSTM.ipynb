{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e22931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# 参数配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEQ_LEN = 24        # 输入序列长度\n",
    "PRED_LEN = 1        # 预测长度\n",
    "BATCH_SIZE = 512\n",
    "num_epochs = 10\n",
    "CNN_CHANNELS = 32   # CNN输出通道数\n",
    "\n",
    "# 数据预处理\n",
    "def load_data(csv_path, seq_len=SEQ_LEN, split_ratio=(0.8, 0.2)):\n",
    "    df = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "    data = df[['OT']].values.reshape(-1, 1)  # 转换为(n_samples, 1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_split = int(len(data) * split_ratio[0])\n",
    "    scaler.fit(data[:train_split])\n",
    "    data_scaled = scaler.transform(data)\n",
    "    \n",
    "    # 创建滑动窗口\n",
    "    X, y = [], []\n",
    "    for i in range(len(data_scaled) - seq_len - PRED_LEN + 1):\n",
    "        X.append(data_scaled[i:i+seq_len])\n",
    "        y.append(data_scaled[i+seq_len:i+seq_len+PRED_LEN])\n",
    "    \n",
    "    X = np.array(X)[:, :, np.newaxis, :]  # 调整为CNN所需的(样本, 序列长度, 通道, 特征)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # 划分数据集\n",
    "    X_train, y_train = X[:train_split], y[:train_split]\n",
    "    X_test, y_test = X[train_split:], y[train_split:]\n",
    "    \n",
    "    # 转换为Tensor并调整维度为(batch, channel, seq_len, feature)\n",
    "    X_train = torch.FloatTensor(X_train).permute(0, 2, 1, 3).to(device)  # (B, C, L, F)\n",
    "    y_train = torch.FloatTensor(y_train).to(device)\n",
    "    X_test = torch.FloatTensor(X_test).permute(0, 2, 1, 3).to(device)\n",
    "    y_test = torch.FloatTensor(y_test).to(device)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test), scaler\n",
    "\n",
    "# 数据集类\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {'input': self.X[idx], 'target': self.y[idx]}\n",
    "\n",
    "# CNN+LSTM模型\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, input_channels=1, cnn_channels=CNN_CHANNELS, \n",
    "                 lstm_hidden=50, output_size=1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv2d(input_channels, cnn_channels, kernel_size=(3, 1), padding=(1, 0))\n",
    "        self.lstm = nn.LSTM(cnn_channels, lstm_hidden, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(lstm_hidden, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, C, L, F) -> (B, C, L, 1)\n",
    "        x = self.cnn(x)  # (B, C, L, 1)\n",
    "        x = x.permute(0, 2, 1, 3).squeeze(-1)  # 转换为(B, L, C)\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])  # 取最后一个时间步输出\n",
    "\n",
    "# CNN+MinLSTM模型\n",
    "class CNNMinLSTM(nn.Module):\n",
    "    def __init__(self, input_channels=1, cnn_channels=CNN_CHANNELS, \n",
    "                 minilstm_hidden=50, output_size=1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv2d(input_channels, cnn_channels, kernel_size=(3, 1), padding=(1, 0))\n",
    "        self.minilstm = MinLSTM(cnn_channels, minilstm_hidden, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, C, L, F) -> (B, C, L, 1)\n",
    "        x = self.cnn(x)  # (B, C, L, 1)\n",
    "        x = x.permute(0, 2, 1, 3).squeeze(-1)  # 转换为(B, L, C)\n",
    "        return self.minilstm(x)  # 输入到MinLSTM\n",
    "\n",
    "# MinLSTM 模型定义\n",
    "class MinLSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.linear = nn.Linear(input_size, hidden_size * 3, bias=False)\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        h_prev = torch.zeros(batch_size, self.hidden_size, device=x.device, dtype=x.dtype)\n",
    "        f, i, h = torch.chunk(self.linear(x), chunks=3, dim=-1)\n",
    "        diff = F.softplus(-f) - F.softplus(-i)\n",
    "        log_f = -F.softplus(diff)\n",
    "        log_i = -F.softplus(-diff)\n",
    "        log_h_0 = self.log_g(h_prev)\n",
    "        log_tilde_h = self.log_g(h)\n",
    "        log_coeff = log_f.unsqueeze(1)\n",
    "        log_val = torch.cat([log_h_0.unsqueeze(1), (log_i + log_tilde_h)], dim=1)\n",
    "        h_t = self.parallel_scan_log(log_coeff, log_val)\n",
    "        output = self.output_layer(h_t[:, -1, :])\n",
    "        return output\n",
    "\n",
    "    def parallel_scan_log(self, log_coeffs, log_values):\n",
    "        a_star = F.pad(torch.cumsum(log_coeffs, dim=1), (0, 0, 1, 0)).squeeze(1)\n",
    "        log_h0_plus_b_star = torch.logcumsumexp(log_values - a_star, dim=1).squeeze(1)\n",
    "        log_h = a_star + log_h0_plus_b_star\n",
    "        return torch.exp(log_h)\n",
    "\n",
    "    def g(self, x):\n",
    "        return torch.where(x >= 0, x + 0.5, torch.sigmoid(x))\n",
    "\n",
    "    def log_g(self, x):\n",
    "        return torch.where(x >= 0, (F.relu(x) + 0.5).log(), -F.softplus(-x))\n",
    "\n",
    "# 训练和评估函数\n",
    "def train_and_evaluate(model, train_dataloader, test_dataloader,\n",
    "                      loss_fn, optimizer, num_epochs=10, scheduler=None):\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    memory_usage = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        training_loss = 0.0\n",
    "        \n",
    "        for idx, batch in enumerate(train_dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "            inputs = batch['input']\n",
    "            targets = batch['target'].squeeze(-1)  # 调整维度\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                peak_mem = torch.cuda.max_memory_allocated()\n",
    "                memory_usage.append(peak_mem)\n",
    "            \n",
    "            training_loss += loss.item()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            if idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Step: {idx}, Train Loss: {training_loss/(idx+1):.4f}')\n",
    "\n",
    "        avg_train_loss = training_loss/len(train_dataloader)\n",
    "        print(f'Epoch: {epoch} => Avg Train Loss: {avg_train_loss:.4f}')\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    avg_memory = sum(memory_usage)/len(memory_usage)/(1024**2) if memory_usage else 0\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred, y_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            inputs = batch['input']\n",
    "            targets = batch['target'].squeeze(-1)\n",
    "            outputs = model(inputs)\n",
    "            y_pred.extend(outputs.cpu().numpy())\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "    \n",
    "    y_pred = scaler.inverse_transform(np.array(y_pred))\n",
    "    y_true = scaler.inverse_transform(np.array(y_true))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    print(f'Test MSE: {mse:.4f}')\n",
    "    \n",
    "    return train_losses, mse, total_time, avg_memory\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据（请替换为实际数据路径）\n",
    "    (X_train, y_train), (X_test, y_test), scaler = load_data(\n",
    "        r'/root/hh/ETT-small/ETTh1.csv'\n",
    "    )\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # 结果存储\n",
    "    results = {}\n",
    "    \n",
    "    # 训练CNN+LSTM模型\n",
    "    print(\"\\n=== Training CNN+LSTM ===\")\n",
    "    cnn_lstm = CNNLSTM().to(device)\n",
    "    \n",
    "    # 初始化权重\n",
    "    for name, param in cnn_lstm.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "        elif 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "    \n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(cnn_lstm.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    \n",
    "    cnn_lstm_losses, cnn_lstm_mse, cnn_lstm_time, cnn_lstm_mem = train_and_evaluate(\n",
    "        cnn_lstm, train_loader, test_loader, loss_fn, optimizer, num_epochs, scheduler\n",
    "    )\n",
    "    \n",
    "    results['CNN+LSTM'] = {\n",
    "        'mse': cnn_lstm_mse,\n",
    "        'time': cnn_lstm_time,\n",
    "        'memory': cnn_lstm_mem,\n",
    "        'losses': cnn_lstm_losses\n",
    "    }\n",
    "    \n",
    "    # 训练CNN+MinLSTM模型\n",
    "    print(\"\\n=== Training CNN+MinLSTM ===\")\n",
    "    cnn_minilstm = CNNMinLSTM().to(device)\n",
    "    \n",
    "    # 初始化权重\n",
    "    for name, param in cnn_minilstm.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param)\n",
    "        elif 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(cnn_minilstm.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    \n",
    "    cnn_minilstm_losses, cnn_minilstm_mse, cnn_minilstm_time, cnn_minilstm_mem = train_and_evaluate(\n",
    "        cnn_minilstm, train_loader, test_loader, loss_fn, optimizer, num_epochs, scheduler\n",
    "    )\n",
    "    \n",
    "    results['CNN+MinLSTM'] = {\n",
    "        'mse': cnn_minilstm_mse,\n",
    "        'time': cnn_minilstm_time,\n",
    "        'memory': cnn_minilstm_mem,\n",
    "        'losses': cnn_minilstm_losses\n",
    "    }\n",
    "    \n",
    "    # 可视化比较结果\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    # 1. 训练损失曲线比较\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(results['CNN+LSTM']['losses'], label='CNN+LSTM Loss', alpha=0.7)\n",
    "    plt.plot(results['CNN+MinLSTM']['losses'], label='CNN+MinLSTM Loss', alpha=0.7)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 2. MSE比较\n",
    "    plt.subplot(1, 3, 2)\n",
    "    models = list(results.keys())\n",
    "    mse_values = [results[model]['mse'] for model in models]\n",
    "    bars_mse = plt.bar(models, mse_values, color=['blue', 'orange'])\n",
    "    \n",
    "    for bar in bars_mse:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Test MSE Comparison')\n",
    "    plt.ylabel('MSE')\n",
    "    \n",
    "    # 3. 训练时间和内存比较\n",
    "    plt.subplot(1, 3, 3)\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1 = plt.subplot(1, 3, 3)\n",
    "    time_values = [results[model]['time'] for model in models]\n",
    "    mem_values = [results[model]['memory'] for model in models]\n",
    "    \n",
    "    bars_time = ax1.bar(x - width/2, time_values, width, label='Training Time (s)', color='blue')\n",
    "    ax2 = ax1.twinx()\n",
    "    bars_mem = ax2.bar(x + width/2, mem_values, width, label='Memory Usage (MB)', color='orange')\n",
    "    \n",
    "    for bar in bars_time:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.2f}s', ha='center', va='bottom')\n",
    "    \n",
    "    for bar in bars_mem:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.2f}MB', ha='center', va='bottom')\n",
    "    \n",
    "    ax1.set_xlabel('Models')\n",
    "    ax1.set_ylabel('Time (s)')\n",
    "    ax2.set_ylabel('Memory (MB)')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(models)\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印详细比较结果\n",
    "    print(\"\\n=== 性能比较汇总 ===\")\n",
    "    print(f\"{'模型':<12} {'MSE':<10} {'训练时间(秒)':<12} {'内存使用(MB)'}\")\n",
    "    print(\"-\" * 45)\n",
    "    for model, result in results.items():\n",
    "        print(f\"{model:<12} {result['mse']:<10.4f} {result['time']:<12.2f} {result['memory']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248aca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化比较结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 1. 训练损失曲线及MSE横线\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(results['CNN+LSTM']['losses'], label='CNN+LSTM Loss', alpha=0.7)\n",
    "plt.plot(results['CNN+MinLSTM']['losses'], label='CNN+MinLSTM Loss', alpha=0.7)\n",
    "plt.axhline(y=results['CNN+LSTM']['mse'], color='blue', linestyle='--', \n",
    "            label=f'CNN+LSTM MSE: {results[\"CNN+LSTM\"][\"mse\"]:.4f}')\n",
    "plt.axhline(y=results['CNN+MinLSTM']['mse'], color='orange', linestyle='--', \n",
    "            label=f'CNN+MinLSTM MSE: {results[\"CNN+MinLSTM\"][\"mse\"]:.4f}')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss and Test MSE Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2. 训练时间对比\n",
    "plt.figure(figsize=(8, 5))\n",
    "models = list(results.keys())\n",
    "time_values = [results[model]['time'] for model in models]\n",
    "bars = plt.bar(models, time_values, color=['blue', 'orange'])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Training Time Comparison')\n",
    "plt.ylabel('Time (Seconds)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 3. 内存消耗对比\n",
    "plt.figure(figsize=(8, 5))\n",
    "mem_values = [results[model]['memory'] for model in models]\n",
    "bars = plt.bar(models, mem_values, color=['blue', 'orange'])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2f}MB', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Memory Usage Comparison')\n",
    "plt.ylabel('Memory (MB)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化比较结果\n",
    "# 1. 训练损失曲线（前100步）\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results['CNN+LSTM']['losses'][:100], label='CNN+LSTM Loss', alpha=0.7)\n",
    "plt.plot(results['CNN+MinLSTM']['losses'][:100], label='CNN+MinLSTM Loss', alpha=0.7)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Comparison (First 100 Steps)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2. MSE对比柱状图\n",
    "plt.figure(figsize=(8, 5))\n",
    "models = list(results.keys())\n",
    "mse_values = [results[model]['mse'] for model in models]\n",
    "bars = plt.bar(models, mse_values, color=['blue', 'orange'])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Test MSE Comparison')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 3. 训练时间对比\n",
    "plt.figure(figsize=(8, 5))\n",
    "time_values = [results[model]['time'] for model in models]\n",
    "bars = plt.bar(models, time_values, color=['blue', 'orange'])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Training Time Comparison')\n",
    "plt.ylabel('Time (Seconds)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 4. 内存消耗对比\n",
    "plt.figure(figsize=(8, 5))\n",
    "mem_values = [results[model]['memory'] for model in models]\n",
    "bars = plt.bar(models, mem_values, color=['blue', 'orange'])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.2f}MB', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Memory Usage Comparison')\n",
    "plt.ylabel('Memory (MB)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
